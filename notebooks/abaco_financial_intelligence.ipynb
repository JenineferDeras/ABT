{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b32a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Any, Dict, List, NamedTuple, Optional\n",
    "feature_frame = globals().get(\"feature_frame\", pd.DataFrame())\n",
    "alerts_frame = globals().get(\"alerts_frame\", pd.DataFrame(columns=[\"customer_id\", \"rule\", \"severity\", \"details\"]))\n",
    "master_frame = globals().get(\"master_frame\")\n",
    "\n",
    "def _build_sample_master_frame() -> pd.DataFrame:\n",
    "    return pd.DataFrame({\n",
    "        \"customer_id\": [\"CUST001\", \"CUST002\", \"CUST003\"],\n",
    "        \"date\": [\"2024-01-01\", \"2024-01-01\", \"2024-01-01\"],\n",
    "        \"balance\": [100000, 50000, 25000],\n",
    "        \"credit_limit\": [150000, 75000, 30000],\n",
    "        \"dpd\": [0, 45, 95],\n",
    "        \"product_code\": [\"CC\", \"PL\", \"CC\"],\n",
    "        \"origination_date\": [\"2023-01-01\", \"2023-06-01\", \"2023-12-01\"],\n",
    "        \"industry\": [\"Technology\", \"Manufacturing\", \"Government\"],\n",
    "        \"kam_owner\": [\"KAM001\", \"KAM002\", \"KAM001\"]\n",
    "    })\n",
    "if master_frame is None or getattr(master_frame, \"empty\", True):\n",
    "    master_frame = _build_sample_master_frame()\n",
    "    print(\"Created sample master_frame with\", len(master_frame), \"records\")\n",
    "\n",
    "DELINQUENCY_BUCKETS = [-np.inf, 0, 30, 60, 90, 120, np.inf]\n",
    "DELINQUENCY_LABELS = [\"current\", \"1_30\", \"31_60\", \"61_90\", \"91_120\", \"120_plus\"]\n",
    "SEGMENT_LABELS = list(\"ABCDEF\")\n",
    "\n",
    "class FeatureArtifacts(NamedTuple):\n",
    "    features: pd.DataFrame\n",
    "    alerts: pd.DataFrame\n",
    "\n",
    "class FeatureEngineer:\n",
    "    def __init__(self, reference_date: Optional[pd.Timestamp] = None) -> None:\n",
    "        self.reference_date = reference_date or pd.Timestamp.utcnow().normalize()\n",
    "\n",
    "    def _derive_customer_type(self, frame: pd.DataFrame) -> pd.Series:\n",
    "        if \"customer_type\" in frame.columns:\n",
    "            return frame[\"customer_type\"].fillna(\"unspecified\")\n",
    "        balance = frame.get(\"balance\")\n",
    "        if balance is None:\n",
    "            balance = pd.Series(0, index=frame.index)\n",
    "        elif not isinstance(balance, pd.Series):\n",
    "            balance = pd.Series(balance, index=frame.index)\n",
    "        balance = balance.fillna(0)\n",
    "        exposure = frame.get(\"credit_limit\")\n",
    "        if exposure is None:\n",
    "            exposure = balance.clip(lower=1)\n",
    "        elif not isinstance(exposure, pd.Series):\n",
    "            exposure = pd.Series(exposure, index=frame.index)\n",
    "        exposure = exposure.where(exposure.notna() & (exposure != 0), balance.clip(lower=1))\n",
    "        ratio = balance / exposure.replace({0: np.nan})\n",
    "        derived = np.where(\n",
    "            balance >= 5_000_000,\n",
    "            \"enterprise\",\n",
    "            np.where(balance >= 500_000, \"corporate\", np.where(balance >= 50_000, \"sme\", \"micro\"))\n",
    "        )\n",
    "        derived = np.where(ratio >= 0.9, \"intensive\", derived)\n",
    "        return pd.Series(derived, index=frame.index)\n",
    "\n",
    "    def _segmentation(self, frame: pd.DataFrame) -> pd.Series:\n",
    "        try:\n",
    "            unique = frame[\"balance\"].nunique()\n",
    "            buckets = min(6, unique)\n",
    "            return pd.qcut(frame[\"balance\"], q=buckets, labels=SEGMENT_LABELS[: buckets], duplicates=\"drop\").astype(str)\n",
    "        except Exception:\n",
    "            return pd.Series([\"A\"] * len(frame), index=frame.index)\n",
    "\n",
    "    def _delinquency_bucket(self, frame: pd.DataFrame) -> pd.Series:\n",
    "        if \"dpd\" in frame.columns:\n",
    "            dpd_source = frame[\"dpd\"]\n",
    "        else:\n",
    "            dpd_source = frame.get(\"days_past_due\", pd.Series(0, index=frame.index))\n",
    "        if not isinstance(dpd_source, pd.Series):\n",
    "            dpd_source = pd.Series(dpd_source, index=frame.index)\n",
    "        dpd_series = pd.to_numeric(dpd_source, errors=\"coerce\").fillna(0)\n",
    "        return pd.cut(dpd_series, bins=DELINQUENCY_BUCKETS, labels=DELINQUENCY_LABELS, right=True)\n",
    "\n",
    "    def transform(self, frame: pd.DataFrame) -> FeatureArtifacts:\n",
    "        if frame.empty:\n",
    "            empty_alerts = pd.DataFrame(columns=[\"customer_id\", \"rule\", \"severity\", \"details\"])\n",
    "            return FeatureArtifacts(frame.copy(), empty_alerts)\n",
    "        prepared = self._prepare_base_features(frame.copy())\n",
    "        enriched = self._compute_financial_metrics(prepared)\n",
    "        alerts = self._collect_alerts(enriched)\n",
    "        return FeatureArtifacts(features=enriched.reset_index(drop=True), alerts=alerts)\n",
    "\n",
    "    def _prepare_base_features(self, features: pd.DataFrame) -> pd.DataFrame:\n",
    "        features[\"date\"] = pd.to_datetime(features[\"date\"], errors=\"coerce\", utc=True)\n",
    "        features[\"customer_type\"] = self._derive_customer_type(features)\n",
    "        features[\"segment_code\"] = self._segmentation(features)\n",
    "        features[\"delinquency_bucket\"] = self._delinquency_bucket(features).astype(str)\n",
    "        features[\"dpd\"] = self._normalize_dpd(features)\n",
    "        return features\n",
    "\n",
    "    def _compute_financial_metrics(self, features: pd.DataFrame) -> pd.DataFrame:\n",
    "        balance_clip = features[\"balance\"].clip(lower=1)\n",
    "        credit_limit_source = features.get(\"credit_limit\")\n",
    "        credit_limit_series = self._normalize_series(credit_limit_source, features.index, np.nan)\n",
    "        credit_limit_series = pd.to_numeric(credit_limit_series, errors=\"coerce\").where(\n",
    "            lambda s: s.notna() & (s != 0),\n",
    "            balance_clip\n",
    "        )\n",
    "        utilization = features[\"balance\"] / credit_limit_series\n",
    "        features[\"utilization_ratio\"] = utilization.replace([np.inf, -np.inf], np.nan).clip(upper=5).fillna(0)\n",
    "        features[\"apr\"] = self._prepare_apr(features)\n",
    "        balance_share = features.groupby(\"customer_id\")[\"balance\"].transform(\n",
    "            lambda values: values / values.sum()\n",
    "        ).fillna(0.0)\n",
    "        features[\"weighted_apr\"] = balance_share * features[\"apr\"]\n",
    "        zscore = (features[\"balance\"] - features[\"balance\"].mean()) / features[\"balance\"].std(ddof=0)\n",
    "        features[\"balance_zscore\"] = zscore.fillna(0).clip(-3, 3)\n",
    "        features[\"industry\"] = self._normalize_series(\n",
    "            features.get(\"industry\"),\n",
    "            features.index,\n",
    "            \"unspecified\"\n",
    "        ).fillna(\"unspecified\")\n",
    "        features[\"kam_owner\"] = self._normalize_series(\n",
    "            features.get(\"kam_owner\"),\n",
    "            features.index,\n",
    "            \"unassigned\"\n",
    "        ).fillna(\"unassigned\")\n",
    "        industry_lower = features[\"industry\"].str.lower()\n",
    "        features[\"b2g_flag\"] = industry_lower.str.contains(\"government|public\").fillna(False).astype(int)\n",
    "        origination_source = features.get(\"origination_date\", features[\"date\"])\n",
    "        days_open = (self.reference_date - pd.to_datetime(origination_source, utc=True)).dt.days\n",
    "        features[\"days_since_origination\"] = days_open.clip(lower=0).fillna(0).astype(int)\n",
    "        features[\"roll_rate_key\"] = features[\"customer_id\"].astype(str) + \"_\" + features[\"product_code\"].astype(str)\n",
    "        features = features.sort_values([\"roll_rate_key\", \"date\"])\n",
    "        features[\"prev_dpd\"] = features.groupby(\"roll_rate_key\")[\"dpd\"].shift(1).fillna(0)\n",
    "        features[\"roll_rate_delta\"] = features[\"dpd\"] - features[\"prev_dpd\"]\n",
    "        features[\"roll_rate_direction\"] = np.select(\n",
    "            [features[\"roll_rate_delta\"] > 0, features[\"roll_rate_delta\"] < 0],\n",
    "            [\"deteriorating\", \"improving\"],\n",
    "            default=\"stable\"\n",
    "        )\n",
    "        features[\"alert_usury_micro\"] = ((features[\"customer_type\"] == \"micro\") & (features[\"apr\"] > 0.85)).astype(int)\n",
    "        features[\"alert_high_utilization\"] = (features[\"utilization_ratio\"] > 0.95).astype(int)\n",
    "        features[\"alert_high_dpd\"] = (features[\"dpd\"] >= 90).astype(int)\n",
    "        features[\"alert_pdf_gap\"] = 0\n",
    "        return features\n",
    "\n",
    "    def _collect_alerts(self, features: pd.DataFrame) -> pd.DataFrame:\n",
    "        alerts_records: List[Dict[str, Any]] = []\n",
    "        alert_columns = {\n",
    "            \"alert_usury_micro\": \"critical\",\n",
    "            \"alert_high_utilization\": \"high\",\n",
    "            \"alert_high_dpd\": \"critical\",\n",
    "            \"alert_pdf_gap\": \"medium\"\n",
    "        }\n",
    "        for alert_col, severity in alert_columns.items():\n",
    "            flagged = features[features[alert_col] == 1]\n",
    "            for _, row in flagged.iterrows():\n",
    "                alerts_records.append({\n",
    "                    \"customer_id\": row.get(\"customer_id\"),\n",
    "                    \"rule\": alert_col,\n",
    "                    \"severity\": severity,\n",
    "                    \"details\": f\"DPD={row.get('dpd')}|Util={row.get('utilization_ratio'):.2f}\"\n",
    "                })\n",
    "        if alerts_records:\n",
    "            return pd.DataFrame(alerts_records)\n",
    "        return pd.DataFrame(columns=[\"customer_id\", \"rule\", \"severity\", \"details\"])\n",
    "\n",
    "    def _normalize_series(self, source: Any, index: pd.Index, default: Any) -> pd.Series:\n",
    "        if source is None:\n",
    "            return pd.Series(default, index=index)\n",
    "        if isinstance(source, pd.Series):\n",
    "            return source\n",
    "        return pd.Series(source, index=index)\n",
    "\n",
    "    def _normalize_dpd(self, features: pd.DataFrame) -> pd.Series:\n",
    "        dpd_source = features.get(\"dpd\")\n",
    "        if dpd_source is None:\n",
    "            dpd_source = features.get(\"days_past_due\")\n",
    "        normalized = self._normalize_series(dpd_source, features.index, 0)\n",
    "        return pd.to_numeric(normalized, errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "    def _prepare_apr(self, features: pd.DataFrame) -> pd.Series:\n",
    "        apr_source = features.get(\"apr\") if \"apr\" in features.columns else features.get(\"nominal_rate\")\n",
    "        apr_series = pd.to_numeric(self._normalize_series(apr_source, features.index, np.nan), errors=\"coerce\")\n",
    "        apr_median = apr_series.median(skipna=True)\n",
    "        if pd.isna(apr_median):\n",
    "            apr_median = 0.0\n",
    "        return apr_series.fillna(apr_median).astype(float)\n",
    "\n",
    "feature_engineer = FeatureEngineer()\n",
    "feature_artifacts = feature_engineer.transform(master_frame)\n",
    "feature_frame = feature_artifacts.features\n",
    "alerts_frame = feature_artifacts.alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c3e91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KPI Calculation Engine\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Any, Dict\n",
    "feature_frame = globals().get(\"feature_frame\", pd.DataFrame())\n",
    "alerts_frame = globals().get(\"alerts_frame\", pd.DataFrame(columns=[\"customer_id\", \"rule\", \"severity\", \"details\"]))\n",
    "\n",
    "class KPIEngine:\n",
    "    def __init__(self, frame: pd.DataFrame) -> None:\n",
    "        self.frame = frame.copy()\n",
    "        if not self.frame.empty:\n",
    "            self.frame[\"date\"] = pd.to_datetime(self.frame[\"date\"], utc=True)\n",
    "            self.frame[\"month\"] = self.frame[\"date\"].dt.to_period(\"M\").dt.to_timestamp()\n",
    "\n",
    "    def _ratio(self, numerator: pd.Series, denominator: pd.Series) -> float:\n",
    "        denom = denominator.sum()\n",
    "        if denom == 0:\n",
    "            return float(\"nan\")\n",
    "        return numerator.sum() / denom\n",
    "\n",
    "    def compute(self) -> Dict[str, Any]:\n",
    "        if self.frame.empty:\n",
    "            return {}\n",
    "\n",
    "        result: Dict[str, Any] = {}\n",
    "        current_frame = self.frame.copy()\n",
    "\n",
    "        result[\"aum\"] = current_frame[\"balance\"].sum()\n",
    "        result[\"active_clients\"] = current_frame[\"customer_id\"].nunique()\n",
    "        result[\"credit_lines\"] = current_frame.get(\"credit_limit\", pd.Series(0, index=current_frame.index)).sum()\n",
    "\n",
    "        churn_mask = current_frame.get(\"status\", pd.Series(\"active\", index=current_frame.index)).str.lower().eq(\"churned\")\n",
    "        result[\"churn_rate\"] = churn_mask.mean()\n",
    "\n",
    "        default_mask = current_frame.get(\"default_flag\", pd.Series(0, index=current_frame.index)).astype(int)\n",
    "        result[\"default_rate\"] = default_mask.mean()\n",
    "\n",
    "        dpd_group = current_frame.groupby(\"delinquency_bucket\")[\"balance\"].sum().rename(\"aum\")\n",
    "        result[\"dpd_buckets\"] = dpd_group\n",
    "\n",
    "        result[\"rotation\"] = self._ratio(\n",
    "            current_frame.get(\"payments\", pd.Series(0, index=current_frame.index)),\n",
    "            current_frame.get(\"balance\", pd.Series(0, index=current_frame.index))\n",
    "        )\n",
    "\n",
    "        result[\"weighted_apr\"] = current_frame[\"weighted_apr\"].mean()\n",
    "\n",
    "        result[\"revenue\"] = current_frame.get(\"interest_income\", pd.Series(0, index=current_frame.index)).sum()\n",
    "        result[\"ebitda\"] = current_frame.get(\"ebitda\", pd.Series(0, index=current_frame.index)).sum()\n",
    "\n",
    "        result[\"concentration_top10\"] = (\n",
    "            current_frame.groupby(\"customer_id\")[\"balance\"].sum().nlargest(10).sum() / result[\"aum\"]\n",
    "            if result[\"aum\"]\n",
    "            else float(\"nan\")\n",
    "        )\n",
    "\n",
    "        ltv = current_frame.get(\"ltv\", pd.Series(0, index=current_frame.index))\n",
    "        cac = current_frame.get(\"cac\", pd.Series(np.nan, index=current_frame.index))\n",
    "        current_frame[\"ltv_cac_ratio\"] = np.where(cac.fillna(0) == 0, np.nan, ltv / cac)\n",
    "\n",
    "        channel_col = next((col for col in (\"channel\", \"source_name\") if col in current_frame.columns), None)\n",
    "        if channel_col:\n",
    "            result[\"ltv_cac_by_segment\"] = current_frame.groupby([\"segment_code\", channel_col]).ltv_cac_ratio.mean()\n",
    "        else:\n",
    "            result[\"ltv_cac_by_segment\"] = current_frame.groupby([\"segment_code\"]).ltv_cac_ratio.mean()\n",
    "\n",
    "        result[\"nrr\"] = self._ratio(\n",
    "            current_frame.get(\"recurring_revenue\", pd.Series(0, index=current_frame.index)),\n",
    "            current_frame.get(\"starting_revenue\", pd.Series(1, index=current_frame.index))\n",
    "        )\n",
    "\n",
    "        result[\"nsm\"] = current_frame.get(\"north_star_metric\", pd.Series(0, index=current_frame.index)).mean()\n",
    "\n",
    "        result[\"penetration\"] = self._ratio(\n",
    "            current_frame.get(\"active_products\", pd.Series(0, index=current_frame.index)),\n",
    "            current_frame.get(\"available_products\", pd.Series(1, index=current_frame.index))\n",
    "        )\n",
    "\n",
    "        result[\"b2g_percent\"] = current_frame[\"b2g_flag\"].mean()\n",
    "\n",
    "        status_column = current_frame.get(\"status\", pd.Series(\"active\", index=current_frame.index)).str.lower()\n",
    "        result[\"new_recurrent_recovered\"] = status_column.value_counts(dropna=False)\n",
    "\n",
    "        group_cols = [\"industry\", \"kam_owner\", \"segment_code\", \"customer_type\"]\n",
    "        aggregation = current_frame.groupby(group_cols)[\"balance\"].sum().rename(\"aum\")\n",
    "        result[\"aum_by_group\"] = aggregation\n",
    "\n",
    "        behavior_mask = (current_frame[\"customer_type\"] == \"micro\") & (current_frame[\"apr\"] > 0.85)\n",
    "        result[\"usury_micro_share\"] = behavior_mask.mean()\n",
    "\n",
    "        result[\"pod\"] = current_frame.get(\"probability_of_default\", pd.Series(np.nan, index=current_frame.index)).mean()\n",
    "\n",
    "        if not alerts_frame.empty:\n",
    "            result[\"alerts_active\"] = alerts_frame.groupby(\"severity\").size()\n",
    "\n",
    "        return result\n",
    "\n",
    "kpi_engine = KPIEngine(feature_frame)\n",
    "kpi_summary = kpi_engine.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8df6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marketing & Sales Analysis\n",
    "import pandas as pd\n",
    "from typing import Dict, List\n",
    "feature_frame = globals().get(\"feature_frame\", pd.DataFrame())\n",
    "\n",
    "def marketing_sales_breakdown(frame: pd.DataFrame) -> Dict[str, pd.DataFrame]:\n",
    "    if frame.empty:\n",
    "        return {}\n",
    "\n",
    "    aggregations: Dict[str, pd.DataFrame] = {}\n",
    "    group_fields: Dict[str, List[str]] = {\n",
    "        \"industry\": [\"industry\"],\n",
    "        \"kam\": [\"kam_owner\"]\n",
    "    }\n",
    "    channel_columns = [column for column in (\"channel\", \"source_name\") if column in frame.columns]\n",
    "    if channel_columns:\n",
    "        group_fields[\"channel\"] = channel_columns\n",
    "\n",
    "    for label, fields in group_fields.items():\n",
    "        grouped = frame.groupby(fields, dropna=False).agg(\n",
    "            aum=(\"balance\", \"sum\"),\n",
    "            clients=(\"customer_id\", \"nunique\"),\n",
    "            weighted_apr=(\"weighted_apr\", \"mean\"),\n",
    "            ltv_cac=(\"ltv_cac_ratio\", \"mean\")\n",
    "        ).reset_index()\n",
    "        aggregations[label] = grouped\n",
    "\n",
    "    return aggregations\n",
    "\n",
    "marketing_sales_tables = marketing_sales_breakdown(feature_frame)\n",
    "treemap_ready = marketing_sales_tables.get(\"industry\") if marketing_sales_tables else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d247dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Quality Audit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.formats.style import Styler\n",
    "from typing import Any, Dict, List, Optional, TYPE_CHECKING, cast\n",
    "try:\n",
    "    import pdfplumber  # type: ignore[import-not-found]\n",
    "except ModuleNotFoundError:\n",
    "    pdfplumber = None\n",
    "if TYPE_CHECKING:\n",
    "    import pdfplumber as _pdfplumber_stub\n",
    "feature_frame = globals().get(\"feature_frame\", pd.DataFrame())\n",
    "\n",
    "CRITICAL_COLUMNS = {\"customer_id\", \"date\", \"balance\", \"dpd\"}\n",
    "\n",
    "def data_quality_audit(frame: pd.DataFrame) -> Dict[str, Any]:\n",
    "    if frame.empty:\n",
    "        return {\"score\": np.nan, \"table\": pd.DataFrame(), \"styled\": None, \"pdf_completeness\": 0.0}\n",
    "\n",
    "    total_rows = len(frame)\n",
    "    audit_records: List[Dict[str, Any]] = []\n",
    "    penalties = 0.0\n",
    "\n",
    "    for column in frame.columns:\n",
    "        nulls = frame[column].isna().sum()\n",
    "        zeros = (frame[column] == 0).sum() if pd.api.types.is_numeric_dtype(frame[column]) else np.nan\n",
    "        coverage = 1 - (nulls / total_rows) if total_rows else np.nan\n",
    "        if column in CRITICAL_COLUMNS and coverage < 0.9:\n",
    "            penalties += 0.1\n",
    "        audit_records.append(\n",
    "            dict(column=column, nulls=int(nulls), zeros=int(zeros) if not pd.isna(zeros) else np.nan, coverage=coverage)\n",
    "        )\n",
    "\n",
    "    audit_table = pd.DataFrame(audit_records)\n",
    "    coverage_mean = audit_table[\"coverage\"].mean()\n",
    "    quality_score = max(0.0, min(1.0, (coverage_mean if not pd.isna(coverage_mean) else 0.0) - penalties))\n",
    "\n",
    "    def _color(value: float) -> str:\n",
    "        if pd.isna(value):\n",
    "            return \"color: #E6E6EF; background-color: #3730A3\"\n",
    "        if value >= 0.95:\n",
    "            return \"color: #05101a; background-color: #22E7CC\"\n",
    "        if value >= 0.85:\n",
    "            return \"color: #F5F3FF; background-color: #2563EB\"\n",
    "        return \"color: #F5F3FF; background-color: #B91C1C\"\n",
    "\n",
    "    styler = audit_table.style.format({\"coverage\": \"{:.2%}\"})\n",
    "    apply_map = getattr(styler, \"applymap\", None)\n",
    "    styled = apply_map(_color, subset=[\"coverage\"]) if callable(apply_map) else styler\n",
    "\n",
    "    pdf_completeness = 1.0 if pdfplumber else 0.0\n",
    "\n",
    "    return dict(score=quality_score, table=audit_table, styled=styled, pdf_completeness=pdf_completeness)\n",
    "quality_artifacts = data_quality_audit(feature_frame)\n",
    "quality_score = quality_artifacts.get(\"score\")\n",
    "quality_table = quality_artifacts.get(\"table\")\n",
    "quality_styled = quality_artifacts.get(\"styled\")\n",
    "\n",
    "print(f\"Data Quality Score: {quality_score:.2%}\" if not pd.isna(quality_score) else \"Data Quality Score: N/A\")\n",
    "print(f\"PDF Completeness: {quality_artifacts.get('pdf_completeness', 0.0):.1%}\")\n",
    "\n",
    "if quality_styled is not None:\n",
    "    display(quality_styled)\n",
    "else:\n",
    "    print(\"No data quality table to display - feature_frame is empty\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
